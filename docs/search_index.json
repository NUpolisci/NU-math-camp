[["index.html", "Computational Programming for the Social Sciences Chapter 1 Welcome! 1.1 Requirements 1.2 Questions or Comments", " Computational Programming for the Social Sciences Sarah Moore and Jean Clipperton 2022-08-28 Chapter 1 Welcome! This text is a guide to thinking about data and its analysis in R and Python for students of the social sciences. Included in this text are elementary introductions into computational programming languages that are useful for performing data management and quantitative statistical analyses. This text should serve as a companion to our main text: Introductory Probability and Statistics for Social Sciences. These texts are jointly authored by Jean Clipperton and Sarah Moore to serve in the Northwestern University Political Science and Sociology graduate student methodological curriculum. To develop these texts and the graduate student curriculum, we have relied on some core sources: YaRrr! The Pirate’s Guide to R by Nathaniel Phillips Advanced R, First and Second Editions by Hadley Wickham ggplot2: Elegant Graphics for Data Analysis by Hadley Wickham Sean Kross’s guide to bookdown 1.1 Requirements As a prerequisite, the tutorials in this text require that you download R, RStudio IDE, Python, and PyCharm to interface with the pertinent coding languages– R and Python. Later sections will go into more detail regarding how to load and interact with these programs on your computer, but please ensure that you have sufficient storage and computing power to operate these programs. Additional activities will require that you become familiar with GitHub, LaTeX, and additional computational packages that are downloaded ad hoc in their respective programming platform. We further suggest that you familiarize yourself with StackExchange or StackOverflow. Stack sites host incredibly helpful message boards for troubleshooting problems related to really anything, but here we emphasize their usefulness for questions related to statistics and programming. It’s likely that one of your many questions you will have are already answered on Stack! 1.2 Questions or Comments This text is updated regularly and we welcome all suggestions toward its improvement. Please email one of the authors, Sarah Moore or Jean Clipperton, with your comments. "],["ch2.html", "Chapter 2 Getting Started 2.1 Installing and Familiarizing Yourself with R and RStudio 2.2 Installing and Familiarizing Yourself with Python 2.3 Moving Forward", " Chapter 2 Getting Started In this chapter: Installing R and RStudio IDE Starting a script in RStudio Installing Python and Pycharm IDE Starting a new project and Python script in PyCharm 2.1 Installing and Familiarizing Yourself with R and RStudio Before working through any of the remaining text you will need to complete a couple of crucial steps. You need to ensure that you have access to all of the computational programs that the text will cover. First, we will cover the installation of R and the RStudio integrated development environment. 2.1.1 R R is downloadable via the CRAN (Comprehensive R Archive Network). Aside from housing the R base distribution, CRAN also houses additional help files on the myriad packages that are available for download once you have access to the base system– more on that later! You will need to choose the R distribution download suitable for your operating system (i.e. macOS, Windows, or Linux). Go ahead and follow the instructions at the download link, ensure that the program downloads properly, and stored in a familiar location on your computer. 2.1.2 RStudio Next, visit the RStudio site. RStudio is an environment that makes working in R and other programs a little more manageable. As you might have seen if you opened R after download, the base R platform is very simple. RStudio instead has a structured setup that allows for file and visualization management, cataloging package help files, and integration with additional programs in a single screen, all while still maintaining the basic functionality of R. When downloading RStudio, it is up to you whether you use the Server or Desktop version. Once you make your choice among these options, follow the download guidelines given your operating system and ensure again that the program stores in a familiar location on your computer. 2.1.3 Navigating RStudio Upon completing download of both R and RStudio, you may open up RStudio and browse around. You will see that the RStudio interface has 4 primary panes. Basic RStudio Pane Layout In the SOURCE pane, you will write editable and savable scripts of code. RStudio further lets you operate with different types of source codes depending on the specific script file that you open. We will visit this later when we talk about RMarkdown and other potential uses of RStudio outside of analyses. All R source code has the file format “.r”. To run a line of code, you can either click the Run button at the top of the script pane, or press Cmd/Ctrl + Enter on your keyboard, while your cursor is on the line of code. To run chunks of your script, you can highlight the relevant code and then perform this same operation while the code text is highlighted. To run the full script you can simply press Cmd/Ctrl + Shift + Enter. Commenting on your code is one of the most important practices to develop early on in programming. To do so in R, simply begin a line of code with #. This will prevent the program from running whatever is written at that line in the script. Note that for every line of comments you will need to input a new #. # Imagine here is where I am going to put information about this variable. wars_1920 # And here is where I will explain why I ran this test. t.test(wars_1920~industrial) The CONSOLE is the default location to display code output as well as previously run code. You can also run code in the console itself, however this is not advisable as earlier codes cannot be edited, and you cannot save an editable script as is possible in the source pane. Running code sometimes also takes a long time or is prone to bugs, while you run code a STOP sign will appear in the upper right hand corner of the console. Should you need to force stop code, pressing this stop button should discontinue the operation. The R ENVIRONMENT contains the names and details of all objects that have been programmed into R’s local memory. For example, let’s say you created a variable named potatoes that contained the names of all different types of potatoes. The environment pane would contain this variable name and some meta-data about how many different values were observed in the variable (e.g. the variable length). Or, let’s say you imported a dataset called potato_information. In the case of the dataset, the environment tab would provide information on the dimensions of the dataset given the number of total variables and observations. The R environment panel also has a few other tabs for history, connections, Git, and object viewing. These tabs are not immediately relevant and we will address them later in the text, as necessary. Data Source The FILES, PLOTS, PACKAGES, HELP is another multi-use pane, with tabs that will likely all be relevant to you. The Files tab will allow to open and interact with files that are available in your directories accessible from your local, git, or cloud workspace. The Plots tab displays all the image or graph outputs from the source code. The Packages tab lists all the installed packages, with checkboxes that indicate whether or not the package has been loaded for use. Finally, the Help tab allows access to all R package help files avaible on the CRAN. You can query a specific package’s help file in the search bar on the Help tab, or you can call for a specific help file in the source code or console. More on these topics will be addressed in the chapters to come. You can customize the available tabs. For example, you might integrate your Git account with RStudio, as we cover later. This and other custom features are available to play around with in the RStudio Preferences. To begin writing and editing code in R, you will click the blank page icon in the top left hand corner. When a drop down menu gives you a number of options to choose from, choose R Script. There are other options of new sheets that you can open and edit in R, but for now we will focus on the most basic script. From now and through the rest of this course, you should assume that R usage and coding activities will be moderated via RStudio, as opposed to the base R program. 2.1.4 Why R? Oftentimes, students ask why they will learn R rather than other potential statistical analysis programs, such as STATA. The easy and clearest answer is that R and it’s cognate applications are all open source. This means that R and any additional packages in R are free to use. In addition to being free, open source coding also means that the back-end development codes are open and free to reproduce and modify. R’s package diversity, data visualization capabilities, and relative age to other programs are also reasons that we might argue for the emphasis on R. Other open source languages, such as Python, are quickly becoming relevant to social scientists in both academic and non-academic contexts. However, these languages are not yet as widely popular. Therefore, it may take some time before languages such as Python become as accessible and necessary for training in quantitative social science. 2.2 Installing and Familiarizing Yourself with Python As graduate education modernizes itself toward training for both academic and non-academic jobs, teaching programming literacy beyond just R is essential. So, we will also cover some basics of the Python coding language as well. As mentioned, Python is newer on the scene generally and especially among social sciences. This means that resources available to make Python legible to social scientists in training is still being built up. We hope that some of the text here at least exposes you enough to Python and one available Python interface such that you might pursue further training later on, if desired. 2.2.1 Python First, if you are a Windows user you will download the latest version of Python, or at least Python 3. Just like R and RStudio, be sure to download the correct version for your operating system. Mac and Linux users already have Python, but if you run into any problems just try and download Python. Once you have downloaded Python, make sure you downloaded it to a location on your computer that makes it easy to find again. Otherwise, there is no need to open any program after download. 2.2.2 PyCharm IDE Just like with R and RStudio, we will rely on an integrated development environment to help cushion the interaction with Python, which otherwise has a very minimalist interface. PyCharm is a great IDE for beginners that don’t want to stick to RStudio for Python projects, but still want a well-built environment. We encourage you to check out Reddit and other message board threads on what IDEs might be better suited for your particular goals with Python as you become more familiar with it. Visit the PyCharm site, download the suitable version, and read through the documentation. There are a couple of different versions for download, we recommend that you opt for the open-source Community version. Though PyCharm is more developed than other potential interfaces for Python, the structure is still quite opaque for those new to coding– even for those of us that have been around R for a while. So read through what you can about getting started, and when we revisit Python in later chapters, we hope that things will come together smoothly. When you open PyCharm, you will be prompted to start a new project, open an existing project in a local working directory, or work with a project in version control. For now, start a new project without modifying any of the additional selections in the prompt. Once you hit “Create” you will encounter the following screen: On the left hand side is a file tree, with all project related scripts and files. The right hand side is the source script or editable code. In the case that you want to start a new Python script instead of the welcome script shown here, simply choose File \\(\\rightarrow\\) New… \\(\\rightarrow\\) Python File. As you may notice, Python code files have the file format “.py”. Along the bottom edge, you will see a few options to toggle for additional panels related to version control, to dos, packages, etc. All in all, it is much like the pane system integrated into RStudio. PyCharm has additional add-ons that you can generate and customize yourself. Again, we recommend that you take a look at the documentation on the PyCharm site should you want to be more advanced in that environment. 2.3 Moving Forward The remainder of this text will focus primarily on R and then later on some basics of Python. But first we are going to take a quick detour into Github and LATEX: two additional software distributions that will also be important to develop scientific research both in and out of academia. "],["ch3.html", "Chapter 3 Documentation with LATEX 3.1 LATEX: It’s pronounced LAH-tekh or LAY-tekh 3.2 Your First LATEX Overleaf Project 3.3 The Anatomy of a TeX-style document 3.4 Adding dimension to a base document", " Chapter 3 Documentation with LATEX In this chapter: What is LATEX and why use it? Let’s make this simple: Using Overleaf to create TEX-style documents Working with templates Conventions in LATEX Portions of this chapter were derived from Learn LaTeX in 30 minutes available on Overleaf–please check out this resource! 3.1 LATEX: It’s pronounced LAH-tekh or LAY-tekh LATEX is a document preparation program that allows you to easily develop documents in plain text that are later compiled into PDF form. Most word processors follow a “What You See Is What You Get” preparation– the page you see typed is the final product. LATEX instead uses an underlying computational software to turn the typed plain text into a user-specified style output that can easily be changed to conform to your desired specifications, or those of academic journals. With LATEX, formatting tables, writing equations, and auto-formatting section and figure labels becomes a breeze. What this all means will become more clear as we explore further. There are many distributions that will help you navigate the creation of LATEX documents, including even some features in R. However, online programs are becoming more useful and transportable means to navigate the LATEX environment. So, instead of asking you to download any software, we’ll instead direct you to go to Overleaf, an online TeX editor that is also a collaborative environment. Overleaf makes it easy to see document history, discover templates for specific document types (e.g. CVs or posters) or journal submission requirements, and access your projects from many different machines without having to download LATEX on each of them. Throughout this course, and likely others, you will use LATEX to format and compile your homework assignments. In many cases, your homework problems are already typeset into a LATEX document, all that you will be required to do is format the answers in the same document and compile the document (i.e. convert the document into a PDF) to turn in via email or on Canvas. In the case that you would instead like to explore a software option for LATEX on your home computer, you can check out TinyTeX. 3.1.1 Getting Set Up on Overleaf To get started, you will need to create an Overleaf account. This is straightforward. A premium plan is likely not necessary right now, though you might consider looking into the more advanced plans later. The premium student plan is available for only $8/month. Once you have created your account and logged in, you will encounter your main page. One day it will be filled with all of your works in progress, but for today it should look something like this: Overleaf Demo As you can see, this site is pretty easy to navigate and we’ll leave it up to you to explore a little bit. 3.2 Your First LATEX Overleaf Project To get started, choose the New Project button in green on the left-hand side of the page. In the drop-down menu, choose “Example Project” and name the project something like “2022_Tutorial_LASTNAME”. Once you select Create, the new project will open. On this project page, the far left-hand side is a file tree of all the images, .tex files, or other necessary components needed to compile the final document (this will make sense, we promise!!). The middle pane is your plain text file. At start-up, this file will be named “main.tex”– all plain text files that you want to render in a pdf end in “.tex”. The “main.tex” file is where you will want to input all of the text that you wish to publish for this particular document. Overleaf Main .tex File The right-hand pane is a preview of your rendered document given the formatting specifications given in “main.tex”. Overleaf Compiled File This example document provided by Overleaf will go a long way in showing you the intricacies of preparing a TeX-style document. Here, we’ll go over some of the main points to ensure you can at least turn in the first few homework assignments without an issue. 3.3 The Anatomy of a TeX-style document This section will assume that you are still viewing the same tutorial document accessed in the previous section. Here we will discuss a bit about the composite elements of a TeX document required to successfully compile. A compiled TeX file is one that made the journey from plain file to PDF rendered document. The beginning of every .tex file will start with a preamble. The preamble is the section where you specify the document class, details you would like to implement throughout the document, and define the parameters of elements that might appear in the text. The preamble is also important for indicating which packages that you would like LaTeX to use to create certain features of your text. Packages are simply additional code components developed to make certain features more feasible without requiring that users code all the specifications themselves. Different packages are useful for modifying the design and layout of things like tables or sections with multiple column. In the tutorial .tex document on Overleaf, the following text composes the preamble, which is not published text. After the preamble, the code \\begin{document} begins the section of published text. \\documentclass{article} % Language setting % Replace `english&#39; with e.g. `spanish&#39; to change the document language \\usepackage[english]{babel} % Set page size and margins % Replace `letterpaper&#39; with `a4paper&#39; for UK/EU standard size \\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry} % Useful packages \\usepackage{amsmath} \\usepackage{graphicx} \\usepackage[colorlinks=true, allcolors=blue]{hyperref} \\title{Your Paper} \\author{You} \\begin{document} Two elements of this preamble are absolutely necessary in all cases. The codes \\documentclass{} and \\begin{document} are required of all documents. Additionally, \\end{document} is always required at the end of the text to ensure that the document compiles. The remaining packages are loaded in via the command \\usepackage{}. We won’t cover anything else related to class=“latex”&gt;LATEX packages here, as there are a multitude of them and each has their own documentation The text between the commands \\begin{document} and \\end{document} is the body. The body of the text is exactly as you specify it to be! While this is where you will type all of the relevant text you want to typeset, you will also see the body littered with commands and comments. Throughout a .tex file a command will always begin with a back slash \\ followed by the chosen command. To ensure that the command runs properly, you will have to ensure that the accompanying package is included in the preamble. For example, if I wanted to typeset a table with a caption I would specify the command \\begin{table} before the table and formatting text and specify the \\end{table} at the end, the \\caption{} command falling somewhere between. \\begin{table} \\caption{Here is a table about interesting activities in Chicago} \\begin{tabularx}{|c|c|} \\hline Actvity &amp; Neighborhood \\\\ \\hline WhirlyBall &amp; Logan Square \\\\ \\hline Nature Conservatory &amp; Lincoln Park or Garfield Park \\\\ \\hline \\end{tabularx} \\end{table} You might also want to comment on your code, or put notes as to what certain packages do as in the preamble above. To do so, you simply begin the comment text with a percentage symbol %. The comment can begin anywhere in the text that you want and is stopped when a new line of text is started (i.e. you must hit Return to end the comment line). 3.3.1 Exercise Change the preamble text in the tutorial document to reflect your authorship and a chosen title. See the commands for \\title{} and \\author{}. Edit the abstract text to describe a few goals you have for this class or your first year of grad school. Recompile the document and take a look at the right-hand pane of Overleaf. Does the newly compiled document reflect your changes? Or do you get an error? 3.4 Adding dimension to a base document Given the above section, you should be able to make sense of the basic elements necessary to compile a TeX document into a PDF. Beyond these necessities, there are a lot of ways to play around with the text to make it more readable and interesting, or to input relevant figures to the text. The tutorial document walks you through many of these issues, such as creating sections, adding figures and tables, lists, and equations. You should walk through each of these sections to ensure that you have an even better grasp of &lt;class=“latex”&gt;LATEX. For now, skip the section on citations and references (2.9), but you will definitely want to come back to this later given Overleaf’s integration with Zotero and Mendeley. There are a couple of things that the Overleaf Tutorial did leave out about altering text that are worth mentioning here. Bold or italic text is included via the commands \\textbf{*text here*} and \\textit{*text here*}, respectively. Further examples are available regarding text features like that in this Overleaf documentation. Moving from typical text processing software to TeX document preparation can be difficult because you can’t always coerce the spacing that you want. Skipping lines does not equate to creating spacing in the resulting PDF. Instead we have to coerce spacing via different commands. To coerce vertical space, you can use the command \\vspace{} with the desired amount of spacing and a unit of measurement. The same can be done to tab spacing, or create horizontal space, via the command \\hspace{}. You can also coerce a line break with \\\\ at the point where you desire the line break. Related to (2), paragraph indenting is not as simple as tabbing as in Word or another word processor. Instead, you can specify this via a command in the document related to indentation for the entire document \\setlength{\\parindent}{}. The argument for this command should specify the length of the desired indent in the points or pt. More here. In an equation environment, you cannot use regular text without breaking the equation. If you want to use text in an equation environment without closing off the equation first, you can use the command \\text{} with the desired regular text. 3.4.1 Exercise Start a new section at the end of the tutorial document that you name Tutorial Workspace. In your new Tutorial Workspace, create a numbered list of skills that you would like to learn by the end of Math Camp. List them in the order of your priority. Using an unnumbered list environment, create a list of supplies that you think might make grad school better. They can be real or imaginary supplies. Create a paragraph where you describe the things that you have learned in Math Camp so far in bold characters. Write a couple sentences about what you are excited about in italics. "],["ch4.html", "Chapter 4 Integrating R with Github", " Chapter 4 Integrating R with Github In this chapter: Very direct: how to fuse RStudio with Github for version control "],["ch5.html", "Chapter 5 Basic R Syntax, Data Types, and Structures 5.1 Writing things in R 5.2 Operators 5.3 Objects and Data Types 5.4 Data Structures", " Chapter 5 Basic R Syntax, Data Types, and Structures In this chapter: Basic R syntax and conventions Base R arithmetic, logical, and Boolean operators Assigning values to objects Data types, structures, and aggregation 5.1 Writing things in R Given that the last chapter gave you the tools to open an R script, you are now ready to get started with writing some basic code. Let’s get started first with some basics on how R operates. R is a mixed programming code that relies on objects and functions to perform user-designated operations. These operations provide an output for our interpretation. We can think of objects like nouns– the ‘things’ we care to analyze; functions are like verbs– the ‘actions’ we want to do with our objects. Bringing it back to the potato example from the first chapter, the variable potatoes is an object. Anything you ask R to do with the variable potatoes is a function. For example, you might want to know what type of variable potatoes is. You would then use the appropriate function class to get this answer. To get objects and functions to interact, you must nest the object into the function call, as shown in the code chunk below. R then responds back with the appropriate answer– which, in this case, you will find that the potatoes variable is of class character. class(potatoes) ## [1] &quot;character&quot; 5.1.1 Some additional conventions 5.2 Operators 5.2.1 Arithmetic Operators Thankfully, R makes use of some already common operators to perform basic mathematical tasks before having to rely on more complex function calls. Arithmetic operators will form the basis of most math functions; logical operators will be useful to separate out objects while using functions or operators. You are probably familiar with most of the base arithmetic operators: Operator Use + Addition - Subtraction * Multiplication / Division ^ Expontentiation x %% y Modulus (Finding a remainder) x %/% y Integral Division (uncommon) X %*% Y Matrix Multiplication Using the operators standalone means that we can use R as a glorified calculator. The system will perform whatever mathematical operation that you run, following algebraic order of operations, or PEMDAS. For example, you can input the following arithmetic into either the R console or run in a script to obtain the following answers: 4*3^2 ## [1] 36 (4*3)^2 ## [1] 144 100-45+24/2 ## [1] 67 (100-45+24)/2 ## [1] 39.5 24%%2 ## [1] 0 If any of the answers returned by R are puzzling or you are unsure why certain answered were obtained based on slight differences, it may be time to check up on your arithmetic skills based on (Chapter X)[other book] in the accompanying textbook. 5.2.2 Boolean and Logical Operators Logical and Boolean operators are also important to coding in R. Sometimes you will need to separate or join data in logical ways. Or, you might want to index through data to find if certain conditions about the data are true. A lot of this verbiage will be familiar from Chapter X in [] because these operations are an applied form of set theoretic notation. Below is a list of the most common Logical and Boolean operators and what they indicate. Operator Use | Or &amp; And ! Not == Equals != Does not equal &lt; Less than &gt; Greater than &gt;= Less than or equal to &lt;= Greater than or equal to %in% Is in the set As mentioned, these operators are good tools to partition or join data, as well as setting conditions on operations. We will get more into what that means later, but for now here are some examples of how these operators work to render logical results. 10^10 == 100^5 ## [1] TRUE (10^10 == 100^5) | (10^10 != 100^5) ## [1] TRUE 150 &gt;= 157 ## [1] FALSE Notice how the output is simply a logical analysis as to whether the statement evaluated is TRUE or FALSE. Furthermore, these operations will similarly follow an order of operations as with the arithmetic operators. 5.3 Objects and Data Types In the previous sections, we went over how to perform simple operations using R. However, none of the output rendered was saved for later use. This makes things difficult over time or as your data get larger and more complex. Aside from R’s use as a glorified calculator, R is also a flexible data storage container. It is flexible in the sense that we can easily assign, arrange, and change data that we can assign to objects of our own naming. Objects in R may store data of many different arrangements – simple values, variables with multiple values, data frames containing multiple variables, and more. Generally then, objects are an easy way to store and recall data with some implicit meaning. To create these objects, you must assign value to a variable name using &lt;-. For example, let’s say I want to assign the year 1995 to the variable name my_birthday. To do so I will simply type the intended variable name, the assignment operator, and the relevant value. To make sure that the variable has saved as intended, you can run the code print(my_birthday) to double check the output. my_birthday &lt;- 1995 print(my_birthday) ## [1] 1995 Note how I have done this assignment from left-to-right. This is not necessary, but it is the strong norm except in certain relevant cases for assignment in R. Just as with the arithmetic performed above with actual numbers, these same operations can be performed on variables. Let’s say you also stored the year 1998 in a variable named sib_birthday. To calculate the difference in birth years, you can neatly subtract them from each other. Challenge: You can also place the arithmetic operations with these variables into a function. Let’s say that you want R to return the absolute value of the difference. To do so, you can simply put the desired arithmetic operation with the variable names into the function call abs() as shown in the code below. How does this differ from the previous answer where the output did not specify the absolute value? sib_birthday &lt;- 1998 my_birthday - sib_birthday ## [1] -3 abs(my_birthday - sib_birthday) ## [1] 3 5.4 Data Structures This section contains information adapted from Hadley Wickham’ Advanced R. The values that you assign to objects can be composed of different types of data to create different data structures. We will classify data structures in R based on their dimensionality and whether the data that they contain are homogenous (all data are the same type) or heterogenous (the data are different types). See the below table to understand this classification system, then we’ll go into detail on each of the potential structures and how they fit together. Dimensions Homogenous Heterogenous 1 Atomic Vector List 2 Matrix Data Frame N Array 5.4.1 Atomic Vectors Atomic vectors are the most basic variable component in R. In the table above, you will see that atomic vectors are unidimensional and homogenous. This means that a sequence of a single type or class of data compose a vector. Data classes are the type of data that characterize each individual element of a data structure. Some data are characters or integers, and R has a different way of dealing with each of these different data classes. The following table lists all the data classes and examples of each. 5.4.2 List A list is a less likely data structure compared to atomic vectors, but might become more common as you start assembling and cleaning your own data. Lists are unidimensional and heterogenous. Therefore, lists have different classes of data, but are only composed of the single dimension of elements. list_example&lt;-as.list(c(&#39;gray&#39;, 44.8, 67.9, &#39;purple&#39;, 210.4)) typeof(list_example) ## [1] &quot;list&quot; 5.4.3 Matrices and Arrays 5.4.4 Data Frame Data frames are likely the most common type of data structure that you will encounter in actual data analysis. Data frames are multi-dimensional, heterogenous structures. This means that data frames for different types of data across both rows and columns. Furthermore, the multi-dimensional nature of data frames also allows for us to give our data meta-data of sorts, such as names and labels. "],["ch6.html", "Chapter 6 Functions, Packages, and Doing Stuff with Data 6.1 There’s a package for that: the endless possibilities outside of base R 6.2 Help Files 6.3 Dealing with Twins", " Chapter 6 Functions, Packages, and Doing Stuff with Data In this chapter: Basic anatomy of functions in Base R Installing and importing packages Error messages and navigating help files Basic code debugging 6.1 There’s a package for that: the endless possibilities outside of base R We call the built-in functions that do not require any additional specification or installation “Base R.” However, given the expansion of R’s use across many fields and the rapidly evolving landscape of computational sciences, developers and programmers have built easy-to-install software distributions compatible for use as functions within R. We reference these additional features as packages. Packages typically contain a number of different functions with a similar basic structure that are created with a similar theme or goal in mind. For example, the plm package is specifically for modelling panel data; that is, data that considers the same variables over time. Another example is the package clubSandwich, which estimates additional types of standard errors for different models and tests whether a model is still significant given the updated standard error. Other packages provide additional tools for reshaping and manipulating data, visualizing data, or dealing with less standard forms of data. Nowadays, Base R is really quite limited in what it can achieve relative to some of these additional packages. Therefore, literacy in what certain packages are useful for will be an important skill to develop. Here we will focus on how to install and access these additional packages, with specific emphasis on a package that will be useful in the chapters to come– the tidyverse and dplyr. Both of these are packages that have become typical To perform the initial simple install of a package, you will merely run the call install.packages(\"\"). This call downloads the package from the CRAN, the repository of R related “stuff” we mentioned in Chapter 2. When you run this code, you will see a string of script run in the console. This is normal and not something you really need to pay attention to unless there is an error, which R will alert you of. Some packages take longer than others to install, and oftentimes installing packages requires that R also installs a package’s dependencies. Dependencies are additional packages that are necessary for the specified package to run. In some cases, R will need your further permission to download and install dependencies. On one hand, you can choose to allow the dependencies to be downloaded ad hoc, that is at the time when prompted to download the package dependencies. On the other hand, you can specify that R downloads the dependencies in the original call itself. We have demonstrated both of these options below. Try both of these options in your own script to get a feel of what installing a package looks like! # install the tidyverse package from CRAN without specifying any additional actions install.packages(&#39;tidyverse&#39;) # install the tidyverse package including the package dependencies install.packages(&#39;tidyverse&#39;, dependencies = T) Once you have successfully downloaded a package, you will need to tell R that you want to access that package. Much like objects, packages are only available in R memory during each session. This is to say, if you close R or turn off your computer, etc., you will need to reload every package required for each script. There are two ways to load packages. First, you can simply run the function call library(). Notice here that unlike the install.pacakges() function, the library() call does not require that you put the package name in quotation marks. R has another function call for accessing packages that acts nearly the same as library(): require(). These two codes are nearly interchangeable with a few small differences, library() is preferred here merely out of habit. Alternatively, you can go to the Packages pane in the right-hand, bottom side of RStudio and search for the package that you want to interact with, and check the box next to its name. The second option is less the norm, but is useful if you want to check the package version you are have downloaded. Point-and-Click Method for Package Loading See what happens when you try each of the above options on the package psych, a package you have likely not yet downloaded. # first with library() library(psych) # now with require() require(psych) # now try the point-and-click method in the bottom right-hand pane. More advanced ways are out there to install packages, especially for packages not housed in the CRAN. For example, the devtools package allows you to download packages in development directly from Github. These types of installs are a little out of the scope here, but useful to know about for future development in your programming skills. 6.2 Help Files You will organically learn about the myriad packages necessary to complete the computational work necessary to achieve your analysis goals. These things come up in reading, StackExchange forums, or conversations with grad school colleagues. However, knowing the packages to install is only half the battle. You must also understand the functions available in each package, and the syntax required to run these functions. Packages housed on the CRAN all have easy to access .pdfs called R Documentation that will usually pop up when you search Google for the package name + “R file” or something along those lines. Skimming through the full R documentation is the most thorough way to expose yourself to a new package, but likely overkill in some cases. However, this is recommended as you acquaint yourself with R syntax or in the case that an entire package seems particularly useful for your needs. In the case that you are really just curious or stumped about a particular function, you can access help files directly from R. There are two methods to do this, again one is programmatic and the other is point-and-click in R studio. For this example, let’s think about the dplyr package, which is an auxiliary package you downloaded when you installed tidyverse. dplyr contains the function call anti_join() which merges two datasets based on the rows in one that do not match the other. For those that were paying attention to our chapter on set theory, an anti-join finds the elements of X that are not in Y– or the non-intersecting elements of X. But, knowing what a function does will not necessarily tell you how the syntax goes in the function call and the following methods are ways you might access more information. Specify in R code that you want to know more about the function in the simple call ?&lt;function&gt; or help(). So, in this example you would merely run ?anti_join or help(anti_join). If you’d like to specify which package the function is a part of, because in some cases functions will share the same name, you can also specify the package help(anti_join, package=\"dplyr\"). Visit the Help tab on the bottom, right-hand panel and type the function in question. If there is only one function associated with that name, the appropriate help file will pop up in that pane with the information about the function. If there is more than one function with that name, there will be a list of functions and their respective packages. Click on the hyperlink of the appropriate package/function pair and the help file will pop up in the pane. In either method, R will produce the help files associated with the function in question in the Help pane again on the bottom, right-hand side of the RStudio interface. This help file provides information on the syntax, the definition of each argument in the syntax, and what the output means. Furthermore, these help files include examples, referred to as vignettes, that help you to see the functions in action with some notated code. In most cases, these help files will be sufficient to help you understand how a function works at a basic level. However, if the files are unclear or you need a bit more of a walk through, StackExchange or other forums are better for more detailed information. 6.3 Dealing with Twins As we alluded to in the previous section, sometimes you will encounter two functions that have identical names but you will need to make use of both packages containing these functions in the same script. When this happens, R’s default behavior is to choose one function to prioritize over the other, resulting in one of the functions being masked. Fear not, as you can still coerce R to use your preferred function when writing your script with qualified imports. Let’s again revisit an example in dplyr and another popular package Hmisc. Both of these packages contain functions called summarize(). If you want to be able to use dplyr’s summarize() on one line and then use Hmisc’s on the next, you would merely specify that as part of the function with ::. See below for what this looks like. Note that just because functions share names does not imply that they will perform the same computational operation. # qualified imports in R for packages with twin function names # dplyr&#39;s variant first, let&#39;s summarize the potato_weight variable dplyr::summarize(potatoes_info, mean_pw=mean(potato_weight)) # now let&#39;s use the Hmisc variant Hmisc::summarize(potatoes_info$potato_weight, by=potatoes, FUN=mean) # you can also use this qualified import in your call for a help file ?dplyr::summarize ?Hmisc::summarize "],["ch7.html", "Chapter 7 Working with Existing Data + Making Homebases for R 7.1 The Working Directory and Basic Directory Commands 7.2 Importing Data of All Kinds 7.3 Workflow and Data Management Conventions", " Chapter 7 Working with Existing Data + Making Homebases for R In this chapter: Setting a working directory Importing data and understanding different file types Developing a document workflow and conventions for (re)saving data It is very likely that you will not create every dataset that you work with in R from scratch. In almost all cases, you will want to interact with your home computer or Cloud environments to import data into R. Doing so requires that you tell R what directory you want to pull from and that you have at least a basic understanding of what type of data file you are working with to be able to properly import the file. Furthermore, once you have manipulated data, run your analyses, or created data visualizations, you will want to save these created objects in recognizable and safe places and according to naming conventions that make sense. This chapter will show you how to do these things, as well as discuss some of the key issues to consider around file management. 7.1 The Working Directory and Basic Directory Commands When working in R, your computer has the ability to pull and save files based on file pathways that you have indicated in your coding environment. The call getwd() will tell you where exactly this is, however you can also check this (and change it) by going to the RStudio toolbar and selecting Preferences. As you can see in the evaluation of the below code, the current working directory is in a file pathway related to this project. What is your base working directory when you try to run this code? # print your current working directory getwd() ## [1] &quot;/Users/sarahmoore/OneDrive - Northwestern University/Teaching/2022_MathCamp/403-R_Text&quot; While you could change your working directory in the Preferences menu, the call setwd() offers you more flexibility to change the working directory as needed. The set-up for setwd() will differ on the basis of your operating system, as MacOS and Windows write file paths a little differently. However, the general call is the same in both cases and very straightforward. You merely write out the file path corresponding to the directory that you would like to work in and run the call as you would any other R function. The command setwd() will maintain that working directory until you close that R session or specify otherwise. Unless you have created an R project, which we cover in more detail below, it is best practice to begin every R script with defining your working directory with the setwd() call and then double checking that the pathway is correct with getwd(). It’s also best practice to double check your file path anytime you try to change the directory in the middle of a script. 7.1.1 Special Case: R Projects RStudio has additional features which allow for some more sophisticated project management and directory tools. Specifically, you may have seen the option to Create a project or simply File \\(\\rightarrow\\) New Project… in the File drop-down menu. An R project is a means to create a project directory within an existing local directory on your computer that automatically sets the working directory to the chosen project home folder. For example, when authoring this textbook, we created an R project within an existing folder for Math Camp and Political Science 403 so that all of our classroom documents and corresponding data would be readily available for compilation into the project. Another example might be if you already have an existing dataset on your computer and you would like to run some analysis on data in that dataset. You can choose to create an R project in the same folder as the existing dataset so that you both import data, save code, and export any data or results into the same folder more seamlessly than otherwise. An R project is a pretty attractive option, but what are some cases that it might not be a great idea? R projects probably don’t make sense if your data files are all coming from various sources outside of a single path (this sounds messy…) or if you are working in a shared folder where you don’t yet want to make your code accessible to others. That being said, R projects are really flexible and allow for multiple source files (such as scripts or .Rmd files) all in one easy to locate place, so long as you remember where your original R project is stored. So all that to say, if you know that you will be working with some data and a script more than once, it might be advantageous to just make an R project out of it. 7.2 Importing Data of All Kinds You are most likely used to dealing with data in the form of tables, particularly in Excel with the file extension .xlsx or .csv. However, in the world of data analysis these are only two of the many types of files that you might encounter. Others may include files from other statistical programs, such as .sas, .sav, or .dta from SAS, SPSS, and STATA respectively. Each of these proprietary data file types cannot be merely opened on your computer unless you find some way to read them in through a program like R. There are various ways to do this, each of them having their own advantages and we’ll go over some of your options here. 7.2.1 Read as .txt Information in this section was derived from YarRrr! The Pirate’s Guide to R File types from other statistical analysis programs often contain variable and value labels or other meta-data that help the data to make sense. While this information is great, it might also make the data clunky or not load across platforms properly. Therefore, the most straightforward way to load in data from alternative programs is to treat the file like a .txt file. 7.2.2 Using other packages to load in data If you would like to retain some of the meta-data that files from programs like STATA contain, there are other options beyond the read.table() function. The packages haven, readr, rio, or readxl are some examples of some of the packages that might help with loading in data. Visit this article from ComputerWorld for a great rundown of some other packages that might be helpful toward this end. 7.3 Workflow and Data Management Conventions Reliably saving data and R scripts necessitates that you come up with a transparent management system to save and update your files. Just like when we advised that you should comment on your R script so that your future self remembers what you are doing, you should name and manage your files such that your future self can distinguish certain file iterations. As you continue to add certain skills to your toolbox and amass more files, naming different subsets from totally different source datasets dat or data1 is not helpful so that you or other people can meaningfully access your files at a later time. Instead, as you start to update and save files that you have tinkered with, here are some considerations that you should have in naming files for data storage: Date: Beginning your file name with a date is not necessary, but it does make things easier as naming with dates solves two related problems. First, files with later dates can already be identified as the latest versions on the basis of the date. Second, when you are actually searching for files, you can order your files on the basis of their name. Doing so, you can identify which files are the most recently updated. Sometimes this is more advantageous than naming version numbered because little changes don’t necessitate version numbering updates or the numbering process can become convoluted. Clear, concise names that identify the project and data type: Names like data_2020.dta are not helpful if you had multiple projects that happened in 2020. Instead, name your files along the lines of the type of data you’re storing (e.g. survey, election), pertinent location or entity (e.g. Colombia, Mississippi, UN), and the relevant time horizon of the data (e.g. 2016 election, panel, post-2001). Skip the strange characters and spaces in file names: Characters aside from the underscore, hyphen or dash, and plus sign are not widely savable by different data management systems and cloud services. So just don’t use them! Instead of spaces between words, opt for _ or -. Version control: Often the first, second, or third time that you update something will certainly not always be the last. And you will find that not all potential co-authors or colleagues are managing version control with Github. Therefore, creating naming conventions that identify the version of your data is necessary. Ideally, your naming conventions will also be accompanied by a .txt file or Word document that detail the updates made to each version if you are not also working in Github, along with comments in the R code that detail certain changes. Version control can also be further managed by the date features in your naming covered in (1). These points cover the basic of some considerations you will make when naming files. Whatever the case, pick a system and stick to it. Then, remember to implement it EVERY TIME that you save a new file or updated an existing one. Given these pointers, can you identify which of the following file names are suitable for proper data management and those that need some work? 2018 Survey from Afrobarometer.csv(download) 2021_july21_media_survey_PANEL.csv 22-08-31_ColombiaStateCapacity_Project2020v2.dta ANES_2018_v3.dta 2022-subset: anes.csv 7.3.1 Codebooks!!! One of the most important features of data are not even the data themselves. It’s the codebooks! Codebooks are additional documents that should always be authored alongside a dataset. Good codebooks tell the reader about each variable: the variable’s name, its labels, how the variable is measured, the variable type , and what the values of the variable mean. Without this information, data are really meaningless and not interpretable. Some codebooks will even provide frequency tables of variable values or summary statistics for each variable. When you are downloading data that are not your own, it is always best practice to download the codebook alongside the data and then store it in the same location. Even more importantly, if you find yourself in the position that you are authoring a dataset of your own, always ensure that you write a codebook alongside it too– even if you are the only person that will ever use the data! Making your data accessible and interpretable is important for data management and transparency in scientific decision-making, two related principles of modern scientific discovery that will be important both in and out of academia. If you are more interested in this discussion, especially with regard to workflow we encourage you to check out Coding for Economists by Arthur Turrell. The linked section talks about workflows and tools for transparent and reproducible analyses. "],["ch8.html", "Chapter 8 Beyond Base R: Exploring the tidyverse 8.1 What, why, how of tidyverse 8.2 The Pipe %&gt;%", " Chapter 8 Beyond Base R: Exploring the tidyverse In this chapter: Why tidyverse? The pipe %&gt;% to chain functions and saving intermediate objects join, filter, select, and other modes of merging or subsetting data Data manipulation, wrangling, and transformation Conventions of tidyverse programming An alternative to tidyverse: data.table This chapter will largely rely on Wickham and Grolemund’s R for Data Science for its material. This is a great text that is great to revisit once you have mastered some of the basic concepts of programming in R. 8.1 What, why, how of tidyverse Tidyverse is modern library of packages developed for modern data science. All of the accompanying packages and their underlying functions share similar design and grammar styles, meant for seamless interaction between functions among the library of packages. Packages in the core tidyverse within our scope: dplyr is the modern toolkit for data manipulation. ggplot2 provides a framework and grammar for plotting data of different types and interacting with dplyr verbs to mutate data to make it more graph-able. tidyr helps to consistently and tidily clean data. readr a package for importing rectangular data of different file types. Other packages in the tidyverse you might encounter later: forcats, stringr, tibble, purrr, lubridate, rvest, magrittr. For more information on each of these and the greater power of the tidyverse check out the webpage on these packages. So, why tidyverse over the tried and true base R? While base R is great for some things, it can also be really inefficient and difficult to combine different functions together in a meaningful workflow. The tidyverse package solves some of these inefficiencies given the relationships between packages in the library and the ways that tidyverse packages emphasize piping, or chaining together codes to form sophisticated chains of functions. Given that there is a similar language and interpretation across the tidyverse packages, it makes data analysis and data science a lot easier to manage, as opposed to having a multitude of different packages performing all these different steps in your code. However, the learning curve is high because there is a certain philosophy and grammar to the workflow. Navigating and employing this grammar is necessary to running tidyverse code that works. While this high learning curve can be confusing at times, you will thank yourself for putting the work at the front end of your programming journey because tidyverse’s efficiencies make up for it in the end. 8.1.1 Just one more thing! Before we move an inch further into this chapter, recall how to install and load packages from your R library as we went over in Chapter 6. If you did not install the tidyverse during those activities, do so now! The remainder of this chapter (and much of this text), will assume that you are working with tidyverse functions. After you make sure that you did install tidyverse, make sure that it is loaded via the library() function. Next, you will load the dataset mtcars that is already available in Base R. To do so merely run the function data('mtcars'). This is a play dataset with data from the 1974 Motor Trend US magazine that accounts for different specifications across 32 different cars. We realize this has nothing to do with politics or political science, BUT the dataset is really accessible, fairly small, and has data that span the various types we have already covered in previous chapters. There are also many examples out there using this dataset, so hopefully if you have any more questions you can find answers applied to the mtcars data, making it a bit more comfortable to follow along. 8.2 The Pipe %&gt;% "],["ch9.html", "Chapter 9 Data Visualization and ggplot2 9.1 ggplot2 9.2 The first step of visualizing data: KNOW THE DATA 9.3 Building a plot 9.4 Adding flavor to your base plot", " Chapter 9 Data Visualization and ggplot2 In this chapter: Applying skills from tidyverse to visualizing data in R Defining the type of graph desired via geom_ functions Playing around with ggthemes and other graphical specifications Some suggestions and conventions for data visualization (i.e. Dos and Don’ts) 9.1 ggplot2 In Chapter (@ch8) we talked about the suite of packages that compose the tidyverse. Remember mention of ggplot2? A visualization package so good that we don’t even bother teaching people how to visualize data in base R anymore? Well, in case you missed mention of this fabulous package, fear not. In this chapter we will cover the basics of ggplot2. We won’t go into the underlying philosophy of ggplot2 here and the Grammar of Graphics. But if you are interested in more of this Hadley Wickham’s free online text ggplot2: Elegant Graphics for Data Analysis goes into further details on these points. The book also goes into more detail than we can here on more specialized graph types and specifications. As you move forward, this will be a good resource to revisit. More than just discovering the landscape of ggplot2, this chapter also contains some key takeaways about visualizing data in general. So, even if you prefer base R, matplotlib in Python, or just want to be a careful critic of data visualization in popular publications, this chapter will have good insight regarding what does and does not constitute good data viz practice. Based on our work in the previous chapter, you have already downloaded ggplot2 package. Some others that will be useful for this tutorial are ggrepel, ggthemes, ggtext, and scales. When you get a chance, install those. In the case that your code does not work later on, a missed install on one of these packages might be why. Piping and control over the verbiage from dplyr are pretty necessary to have a good command of ggplot2. So, if you are feeling unsure about those skills, revisit the sections on those items and practice with some more test data. # install all the recommended packages at once install.packages(c(&quot;ggrepel&quot;, &quot;ggthemes&quot;, &quot;ggtext&quot;, &quot;scales&quot;)) 9.2 The first step of visualizing data: KNOW THE DATA This chapter will be largely be an applied walk-through tutorial. Therefore, it is written as if you are working along with the text. While you can just easily copy and paste the code from the text to your R script, you will likely benefit from developing the memory around how to compose a plot code, so try to type the code as we go along. Let’s start out by simply just loading in the tidyverse package, which loads in ggplot2. The data that we will use for this chapter are already loaded in with the package. We will first take a look at the msleep data. This is a dataset that details the sleep behaviors of various mammals gathered by Savage and West (2007). Let’s first get acquainted with the dataset and what kinds of variables we will be handling. Note that as long as you have loaded in ggplot2 or tidyverse via the library() call, you will not have to do anything else to import data. First, we can just check the dimensions of the data with dim(msleep). Here we will see that there are 83 rows of data over 11 columns. This means that there are 83 observations for each of the 11 columns. We can also run tibble(msleep) to see a snippet of the data. Alternatively, you can check out the glimpse() function to see all of the column names. The variable names lead us to believe that the dataset contains a number of identifying traits of each mammal in the data, their sleep and waking patterns, and some other physical information. As we talked about before, codebooks are necessary to understand how data are measured and how to interpret different values. To access the codebook for this dataset you can access the help file via the call ?msleep. library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ── ## ✔ ggplot2 3.3.6 ✔ purrr 0.3.4 ## ✔ tibble 3.1.8 ✔ dplyr 1.0.9 ## ✔ tidyr 1.2.0 ✔ stringr 1.4.0 ## ✔ readr 2.1.2 ✔ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() dim(msleep) ## [1] 83 11 tibble(msleep) ## # A tibble: 83 × 11 ## name genus vore order conse…¹ sleep…² sleep…³ sleep…⁴ awake brainwt ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Cheetah Acin… carni Carn… lc 12.1 NA NA 11.9 NA ## 2 Owl monkey Aotus omni Prim… &lt;NA&gt; 17 1.8 NA 7 0.0155 ## 3 Mountain be… Aplo… herbi Rode… nt 14.4 2.4 NA 9.6 NA ## 4 Greater sho… Blar… omni Sori… lc 14.9 2.3 0.133 9.1 0.00029 ## 5 Cow Bos herbi Arti… domest… 4 0.7 0.667 20 0.423 ## 6 Three-toed … Brad… herbi Pilo… &lt;NA&gt; 14.4 2.2 0.767 9.6 NA ## 7 Northern fu… Call… carni Carn… vu 8.7 1.4 0.383 15.3 NA ## 8 Vesper mouse Calo… &lt;NA&gt; Rode… &lt;NA&gt; 7 NA NA 17 NA ## 9 Dog Canis carni Carn… domest… 10.1 2.9 0.333 13.9 0.07 ## 10 Roe deer Capr… herbi Arti… lc 3 NA NA 21 0.0982 ## # … with 73 more rows, 1 more variable: bodywt &lt;dbl&gt;, and abbreviated variable ## # names ¹​conservation, ²​sleep_total, ³​sleep_rem, ⁴​sleep_cycle ## # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names glimpse(msleep) ## Rows: 83 ## Columns: 11 ## $ name &lt;chr&gt; &quot;Cheetah&quot;, &quot;Owl monkey&quot;, &quot;Mountain beaver&quot;, &quot;Greater shor… ## $ genus &lt;chr&gt; &quot;Acinonyx&quot;, &quot;Aotus&quot;, &quot;Aplodontia&quot;, &quot;Blarina&quot;, &quot;Bos&quot;, &quot;Bra… ## $ vore &lt;chr&gt; &quot;carni&quot;, &quot;omni&quot;, &quot;herbi&quot;, &quot;omni&quot;, &quot;herbi&quot;, &quot;herbi&quot;, &quot;carn… ## $ order &lt;chr&gt; &quot;Carnivora&quot;, &quot;Primates&quot;, &quot;Rodentia&quot;, &quot;Soricomorpha&quot;, &quot;Art… ## $ conservation &lt;chr&gt; &quot;lc&quot;, NA, &quot;nt&quot;, &quot;lc&quot;, &quot;domesticated&quot;, NA, &quot;vu&quot;, NA, &quot;dome… ## $ sleep_total &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.0, 5… ## $ sleep_rem &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0.8, … ## $ sleep_cycle &lt;dbl&gt; NA, NA, NA, 0.1333333, 0.6666667, 0.7666667, 0.3833333, N… ## $ awake &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.0, 1… ## $ brainwt &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.07000, 0… ## $ bodywt &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, 0.04… ?msleep 9.2.1 Exercise Given this basic data exploration and the information from the codebook, what types of variables are each of the following: name sleep_total brainwt vore Categorical variables might be loaded into R by the class factor or character. How are categorical variables classed in this dataset? 9.3 Building a plot Plots in ggplot2 are built on the following elements: Specified dataframe or other data object Chosen aesthetics to map to each axes given aes() A layer identifying what type of graph you want to build given a geom function All additional specifications are auxiliary to the base plot. In the case of the msleep data, let’s say we want to plot a histogram of the vore variable. We will start with specifying the data, then containing the chosen variable in the aes() specification. Because there is only one variable, we only set the specification vore on the x variable argument. To add the geom_bar layer, use +. The plus sign is how you will append new layers to all plots created in ggplot2. For now, just append geom_bar() without adding any additional arguments. # histogram of vore variable, v1 ggplot(msleep, aes(x=vore)) + geom_bar() It is conventional that you would create a new line of code after each + appending a specification on to a plot. We suggest this to make identifying the constitutive parts of a graph easier, which further helps with debugging if certain parts of the code are wonky. Now try to run the same code, but instead make the geom function geom_histogram(). # histogram of vore variable, v2 ggplot(msleep, aes(x=vore)) + geom_histogram() When you run this code, you will still encounter a warning. This is because the function for geom_histogram() is reserved for continuous variables. However, we can still use geom_histogram() in a roundabout way if we choose. Given that vore is a character variable, there is no natural way that ggplot knows to graph it to the x axis. Therefore, we have to specify that we want counts of the specified x variable. You can do this in the geom function by specifying geom_histogram(stat='count'). This will coerce ggplot2 to include each of the categories of the specified variable as a bin on the histogram. Check out the following plot, what happens when you use geom_histogram() now? # histogram of vore variable, v3 ggplot(msleep, aes(x=vore)) + geom_histogram(stat=&#39;count&#39;) 9.3.1 Adding data to the plot There are two ways to add data into your ggplot2 visualization. The first is the basic way that we performed above where you merely make the dataframe the first argument of the ggplot() call. The second way allows you to work with more nuanced versions of your data and works off of a %&gt;% pipe. Instead of making your data an argument in ggplot() the data will precede the plot function with a pipe, as shown in option 2 in the code below. When data is added in this way, the arguments in the ggplot() function skip straight to specifying aes(). # option 1 for adding data to the plot ggplot(data, aes(x,y))+ geom_point() #option 2 for adding data to the plot data %&gt;% ggplot(aes(x,y))+ geom_point() The second option to specify the data source is useful when you want to use mutate(), summarize(), group_by(), or another dplyr verb on a variable in the dataset and then graph the resulting value. For example, in the graph below we can plot the mean sleep_total based on a mammal’s classification in the vore variable. To do so, we create a pipe preceding the ggplot() call that groups the mammals based on their vore attribute, and then summarize the vore variable via the mean() function. # start the pipe with the data msleep %&gt;% group_by(vore) %&gt;% # use group_by() on the grouping variable in question summarize(vore_sleep=mean(sleep_total)) %&gt;% # use summarize() to create an intermediate variable that is the group mean sleep_total ggplot(aes(x = vore, y = vore_sleep))+ # begin the ggplot() call and specify the intermediate variable and grouping variable geom_bar(stat=&quot;identity&quot;) Based on this plot, which type of mammal has the greatest average sleep time? 9.3.2 Basic aes() arguments The aes() function of a ggplot maps the aesthetics of the graph. The most basic of these are the arguments x and y, which will always correspond to the first two arguments of the function. It is unncessary to type the x = and y = arguments, but is always useful just to make sure that you are putting in the correct place. Aside from the basic axes arguments, the aes() function can take a few more specifications that will further add detail to the plot. In case you want to add more data into the main specifications of the plot, you can also specify arguments for color, fill, shape, and size. color: specifies an outline color to put around the geom layer representing the primary (x,y) observation fill: specifies a fill color for the geom layer given a variable outside of the primary (x,y) relationship. Discrete variables will fill solid colors, whereas continuous variables will fill a color scale. shape: behaves similarly to the color and fill functions, but instead changes the shape icon indicated by the geom_ layer, best fit for geom_point() applications size: varies the size of the (x,y) observation indicated in aes() based on a third variable, also likely best fit for geom_point() applications Recall the histogram example from above, where we plotted the counts of the vore variable. We can use the fill argument to specify that we would also like for the graph to show the conservation status within each of the vore groups. In turn, ggplot will return the same histogram with the bars broken up into different colors and an accompanying legend as to what each fill color represents. Check out the code below and try for yourself. ggplot(msleep, aes(x=vore, fill=conservation)) + geom_histogram(stat=&quot;count&quot;) 9.3.2.1 Exercise Now you will have the chance to try one out on your own. The above graph shows the count of mammal membership across each value of vore further broken down by mammal conservation status. Now, graph a histogram of the conservation status of the mammals in the dataset, while also accounting for their vore value. Hint: Switch around the variables in the x and fill arguments in the code from the previous graph. How does this graph differ from the previous example? Now, instead of specifying a fill argument, try using the same variable in the color argument. What is the difference from the graph employing the fill argument? Do the same thing, instead specifying the size or shape arguments. Is there an issue with these graphs? 9.3.3 Basic geom layers As you may have noticed from earlier examples, the geom function has different suffixes which allow you to tell ggplot which type of graph you’d like to plot. In the previous exercise, we worked with two pretty straightforward functions: geom_histogram() and geom_bar(). These are good options when you are dealing with counts, or percentages in the case of the bar graph. But what about for other data? Rather than tell you the uses of these one by one, we can see examples graphically. For illustrating the geom layers, we’ll use another dataset contained within the ggplot2 package called economics. The economics data is a time series dataset with dated information on personal consumption expenditures in billions of dollars (pce), population in thousands (pop), personal savings rates (psavert), median duration of unemployment (uempmed), and number of unemployed people in thousands (unemploy). These six variables are accounted for over 574 observations. geom_point() Creates a scatter plot of points for each (x,y) observation. # create a scatterplot of the median duration of unemployment (x) and personal savings rates (y) ggplot(economics, aes(x = uempmed, y = psavert)) + geom_point() geom_boxplot() Creates a boxplot of the distribution and quartiles of the specified variable(s). If both x and y are specified, one should be a discrete variable and the other should be continuous. This would entail that the distribution of the continuous variable is plotted over the subgroups of the discrete variable. Both options are shown below. # create a boxplot of the distribution of the personal savings rate ggplot(economics, aes(x = psavert)) + geom_boxplot() # create a boxplot of the personal savings rate above and below the median unemployment level economics %&gt;% mutate(unemploy_med=if_else(unemploy&lt;median(unemploy, na.rm=T), 1, 0)) %&gt;% ggplot(aes(x = psavert, y = as_factor(unemploy_med))) + geom_boxplot() 3. geom_line() Creates a line graph and best used for showing data over time. # create a line graph of the median unemployment duration over time ggplot(economics, aes(x = date, y = uempmed)) + geom_line() 4. geom_bar() and geom_histogram() geom_bar() and geom_histogram() behave quite similarly. Though, as we mentioned before, geom_bar() is for the discrete case and geom_histogram() is for the continuous case (though we can coerce it to behave otherwise). Both of these plots can be used to show counts of observations. # create a histogram of the total population in thousands, try different specifications of the `bins` argument in `geom_histogram()` ggplot(economics, aes(x = pop)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(economics, aes(x = pop)) + geom_histogram(bins=100) ggplot(economics, aes(x = pop)) + geom_histogram(bins=10) # create a bar chart of the number of observations above and below the mean population economics %&gt;% mutate(pop_mean= if_else(pop&lt;mean(pop, na.rm=T), 1, 0)) %&gt;% ggplot(aes(x = as_factor(pop_mean))) + geom_bar() Challenge: Based on the above bar graph, do you think that the mean population in the economics data is equal to the median population in the data? There are quite a few more geom functions in ggplot2. However, the remainder are not very useful for beginners. We assume that as you go on, you will look more into the types of plots that are best fit to show your data. You will also get a better hang of troubleshooting your visualizations as time goes on. 9.4 Adding flavor to your base plot All the tools in the previous sections show you how to make a graph using ggplot2 tools. But how do you make it better? You may have noticed in the graphs above that the axes labels are not formatted, there are no value labels, and while the general ggplot2 grey and black theme is not terrible, it is a bit drab. These are quite easy fixes just by adding additional lines to the base ggplot appending + followed by a relevant ggplot function. 9.4.1 Labelling the Axes First, we will start with labelling your x and y axes and adding a title to your graph. There are a couple of different ways to do this, and there may be some contexts in which one way is better than the other. For now, the choice is likely one of preference and efficiency. This is to say, for now use whichever manner seems to be quicker for you to implement. The first way is to specify a line a new function for each label. To do so, we’ll revisit the line graph from above that plots the median duration of employment over time. Using the same graph, first add the line xlab() with a relevant title for the x-axis in quotation marks. Do the same, but instead specify ylab() and a relevant title for the y-axis. Finally, think of a title for the whole graph and run this in quotation marks in the function ggtitle(). Each of these specifications will allow you to add a label to the graph in stepwise fashion. # let&#39;s revisit the line graph showing the duration of median unemployment over time from above # add an x label ggplot(economics, aes(x = date, y = uempmed)) + geom_line() + xlab(&quot;Date&quot;) # add a y label ggplot(economics, aes(x = date, y = uempmed)) + geom_line() + ylab(&quot;Median Unemployment Duration (in Weeks)&quot;) # add a title ggplot(economics, aes(x = date, y = uempmed)) + geom_line() + ggtitle(&quot;Median Unemployment Duration over Time, 1976-2015 (monthly)&quot;) These stepwise functions can all be added line-by-line to produce the specified labels together. # let&#39;s put it all together # can add each as separate lines ggplot(economics, aes(x = date, y = uempmed)) + geom_line() + xlab(&quot;Date&quot;) + ylab(&quot;Median Unemployment Duration (in Weeks)&quot;) + ggtitle(&quot;Median Unemployment Duration over Time, 1976-2015 (monthly)&quot;) But, a potentially simpler way of doing this is just to combine each axis and title function into a single label function, as we’ve shown below. In this case, you can simply specify the labels in the function labs(), with each argument corresponding to a respective axis or the title. There may be complicated cases in which this is less efficient, but for now this code is likely the most efficient so long as the syntax is correct. # or, can opt for a single function to label ggplot(economics, aes(x = date, y = uempmed)) + geom_line() + labs(x = &quot;Date&quot;, y = &quot;Median Unemployment Duration (in Weeks)&quot;, title = &quot;Median Unemployment Duration over Time, 1976-2015 (monthly)&quot;) 9.4.2 Labelling Ticks 9.4.3 Using Palettes and Themes The grey and black default of plots made with ggplot2 isn’t the most appealing for visualizing data. You saw that we can alter these colors by specifying additional variables in the color argument. It’s also possible that we can provide our plot with color palette information to provide more colorful graphics. Additionally, the base ggplot2 font and layout might not be the most interesting to some. If this is the case, the ggthemes package allows you to override the base visualization theme entirely in favor of some alternative. While you could style a theme from scratch on your own, for now these preset themes will be great alternatives if you get bored of the typical ggplot2 plot. As an aside, you can also save a plot as you would any other object. For example, below we’ve saved the median unemployment duration as the object named plot_unemployment. After saving the base plot, you can then simply use the object name and append the additional plot specifications To specify a different theme for a plot, you’ll first need to load the package ggthemes. library(ggthemes) plot_unemployment&lt;- ggplot(economics, aes(x = date, y = uempmed)) + geom_line() + labs(x = &quot;Date&quot;, y = &quot;Median Unemployment Duration (in Weeks)&quot;, title = &quot;Median Unemployment Duration over Time, 1976-2015 (monthly)&quot;) plot_unemployment + theme_economist() plot_unemployment + theme_fivethirtyeight() plot_unemployment + theme_stata() ``` "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
